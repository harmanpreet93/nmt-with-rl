{
  "random_seed": 42,
  "model_file": "../model/new_best_model",
  "target_model": "bert_model",
  "transformer_dropout_rate": 0.1,
  "transformer_batch_size": 128,
  "transformer_epochs": 21,
  "transformer_num_layers": 4,
  "transformer_model_dimensions": 128,
  "transformer_num_heads": 8,
  "transformer_dff": 512,
  "transformer_checkpoint_path": "../model/only_DL",
  "inp_language": "en",
  "target_language": "fr",
  "train_data_path_en": "../data/train_en.txt",
  "train_data_path_fr": "../data/train_fr.txt",
  "val_data_path_en": "../data/test_en.txt",
  "val_data_path_fr": "../data/test_fr.txt",
  "dummy_data_path_en": "../data/dummy_en_sample.txt",
  "dummy_data_path_fr": "../data/dummy_fr_sample.txt",
  "tokenizer_path_en": "../tokenizer_data_en_30k",
  "tokenizer_path_fr": "../tokenizer_data_fr_30k",
  "use_pretrained_emb": false,
  "pretrained_emb_path_en": "../pretrained_embeddings/tf_bert_for_masked_lm_epoch_16_loss_9.00_30k_en.npy",
  "pretrained_emb_path_fr": "../pretrained_embeddings/tf_bert_for_masked_lm_epoch_27_loss_8.78_30k_fr.npy",
  "max_length_en": 80,
  "max_length_fr": 120,
  "lambda_dl": 0.01,
  "lambda_rl": 0.99,
  "user_RL": false,
  "compute_bleu": true
}
