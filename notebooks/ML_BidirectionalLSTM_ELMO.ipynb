{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --no-index --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --no-index numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --no-index tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --no-index matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvVhUeaRO_nA"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "#import tensorflow_datasets as tfds\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import unicodedata\n",
    "import re\n",
    "import gc\n",
    "from collections import Counter\n",
    "#import keras as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ys0Y7XsBO_nY"
   },
   "outputs": [],
   "source": [
    "#physical_devices = tf.config.list_physical_devices('GPU')\n",
    "#physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "#os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import h5py\n",
    "import os\n",
    "import bilm\n",
    "from bilm import Batcher, BidirectionalLanguageModel, weight_layers\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYVG_U1HO_ne"
   },
   "source": [
    "## Preprocessing: Tokenize, clean-up, load, padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4OBlaeO_nf"
   },
   "source": [
    "### Tokenize and clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gEI1uWtjO_nh"
   },
   "outputs": [],
   "source": [
    "# Lower case for the translation\n",
    "# Load original english text as is\n",
    "# install requirement.txt\n",
    "# python -m spacy download fr_core_news_sm\n",
    "# correction of tokenizer.py: add encoding='utf-8' to open method\n",
    "# same thing for punctuation_remover.py\n",
    "# python tokenizer.py --input train.lang2 --output tokenized --lang fr --keep-empty-lines\n",
    "# python punctuation_remover.py --input train.lang2.tok --output tokenized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CpNtsXsjO_nn"
   },
   "source": [
    "### Loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y5nxMfzAO_no"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "textdir = \"data/train/\"\n",
    "fr_text_file = os.path.join(textdir, 'train.lang2')\n",
    "en_text_file = os.path.join(textdir, 'train.lang1')\n",
    "\n",
    "#FILE_NAMES = [\"train.lang1\",\"train.lang2\"]\n",
    "#ELMo_Embeddings = [\"new_ELMo_input_en_embeddings.hdf5\",\"ELMo_emb_fr.hdf5\"]\n",
    "\n",
    "datadir = \"ELMo/\"\n",
    "Elmo_emb_dec_input_file = os.path.join(datadir, 'swb_fr/', 'ELMo_decoder_input_embeddings.hdf5')\n",
    "Elmo_emb_dec_targets_file = os.path.join(datadir, 'swb_fr/', 'ELMo_decoder_output_embeddings.hdf5')\n",
    "\n",
    "fr_vocab_file = os.path.join(datadir, 'swb_fr/', 'vocab.txt')\n",
    "fr_options_file = os.path.join(datadir, 'swb_fr/', 'options_eval_fr.json')\n",
    "    fr_weight_file = os.path.join(datadir, 'swb_fr/', 'swb_weights_fr.hdf5')\n",
    "\n",
    "Elmo_emb_enc_file = os.path.join(datadir, 'swb_en/', 'ELMo_encoder_embeddings_post.hdf5')\n",
    "en_vocab_file = os.path.join(datadir, 'swb_en/', 'vocab.txt')\n",
    "en_options_file = os.path.join(datadir, 'swb_en/', 'options_eval.json')\n",
    "en_weight_file = os.path.join(datadir, 'swb_en/', 'swb_weights_en.hdf5')\n",
    "\n",
    "\n",
    "SOS_ELMo_emb_file = os.path.join(datadir, '../', 'SOS_ELMo_emb.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_elmo_emb = h5py.File(Elmo_emb_enc_file, 'r')\n",
    "fr_elmo_emb = h5py.File(Elmo_emb_dec_input_file, 'r')\n",
    "#fr_elmo_emb_targets = h5py.File(Elmo_emb_dec_targets_file, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD>', '<S>', '</S>', '<UNK>', 'the', 'to', 'of', 'and', 'in', 'a']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab = []\n",
    "with open(en_vocab_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.rstrip().split('\\n')\n",
    "        en_vocab.append(line[0])\n",
    "    f.close()\n",
    "\n",
    "en_vocab = ['<PAD>'] + en_vocab\n",
    "en_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input lang tokens:  165670\n"
     ]
    }
   ],
   "source": [
    "en_word2idx = {v:k for k, v in enumerate(en_vocab)}\n",
    "#print(en_word2idx)\n",
    "num_words_input = len(en_word2idx)\n",
    "print(\"Number of input lang tokens: \",num_words_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD>', '<S>', '</S>', '<UNK>', 'de', '.', ',', 'la', 'et', 'le']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_vocab = []\n",
    "with open(fr_vocab_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.rstrip().split('\\n')\n",
    "        fr_vocab.append(line[0])\n",
    "    f.close()\n",
    "\n",
    "fr_vocab = ['<PAD>'] + fr_vocab\n",
    "fr_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of output lang tokens:  83332\n"
     ]
    }
   ],
   "source": [
    "fr_word2idx = {v:k for k, v in enumerate(fr_vocab)}\n",
    "fr_idx2word = {k:v for k, v in enumerate(fr_vocab)}\n",
    "#print(fr_word2idx)\n",
    "num_words_output = len(fr_word2idx)\n",
    "print(\"Number of output lang tokens: \",num_words_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ELMo embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder embeddings\n",
    "dset = list(en_elmo_emb.keys())[0]\n",
    "encoder_input_sequences = en_elmo_emb[dset][()]\n",
    "en_elmo_emb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 96, 256)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max input sentence length\n",
    "max_input_len = encoder_input_sequences.shape[1]\n",
    "max_input_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9377234 ,  0.11211856, -1.815702  , ..., -1.0165986 ,\n",
       "         0.2566865 , -1.4266841 ],\n",
       "       [ 0.76397216, -0.72957176, -1.2059255 , ..., -0.53055835,\n",
       "        -0.28045744, -1.6430402 ],\n",
       "       [-0.09817386, -2.4250271 ,  1.2986397 , ...,  0.80349994,\n",
       "         0.70233214, -3.0202804 ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder input embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder input embeddings\n",
    "dset = list(fr_elmo_emb.keys())[0]\n",
    "decoder_input_sequences = fr_elmo_emb[dset][()]\n",
    "fr_elmo_emb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 113, 256)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max input sentence length\n",
    "max_out_len = decoder_input_sequences.shape[1]\n",
    "max_out_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3515264 , -0.4155752 , -1.1044897 , ..., -0.6278715 ,\n",
       "         1.9337945 , -1.7928498 ],\n",
       "       [ 1.0957094 ,  0.7679421 ,  1.6110834 , ...,  0.3838907 ,\n",
       "        -0.34145802,  1.4356495 ],\n",
       "       [ 0.7996905 ,  0.6359963 ,  0.70580614, ..., -0.95944005,\n",
       "         1.1262033 , -1.3790954 ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load french train text\n",
    "decoder_target_text = []\n",
    "\n",
    "with open(fr_text_file, 'r', encoding=\"UTF-8\") as fr_file:\n",
    "    for line in fr_file.readlines():\n",
    "        line = line.rstrip().split('\\n')\n",
    "\n",
    "        target_line = line[0]+\" </S>\"\n",
    "        #input_line = \"<S> \"+line[0]+\"\\n\"\n",
    "\n",
    "        #decoder_input_text.append(input_line)\n",
    "        decoder_target_text.append(target_line)\n",
    "    fr_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L’ idée de concilier les différences religieuses semble donc dangereuse . </S>',\n",
       " 'Monsieur le Président , Mesdames et Messieurs , les perspectives financières esquissent la portée des activités de l’ UE pour les années à venir , fournissent un cadre pour ces activités et déterminent leur efficacité . </S>',\n",
       " 'La réticence doit laisser place à une politique stimulante . </S>']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "tokenized_context = [sentence.split() for sentence in decoder_target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_context[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_word(word, encode_dict):\n",
    "    #print(encode_dict.get(word))\n",
    "    if encode_dict.get(word)==None:\n",
    "        if encode_dict.get(word.lower())==None:\n",
    "            return encode_dict.get('<UNK>')\n",
    "        else:\n",
    "            return encode_dict.get(word.lower())\n",
    "    else:\n",
    "        return encode_dict.get(word)\n",
    "    \n",
    "def encode_sequence(seq, encode_dict):\n",
    "    #print([j.lower() for j in seq])\n",
    "    return [get_idx_from_word(j, encode_dict) for j in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_from_idx(idx, decode_dict):\n",
    "    if decode_dict.get(idx)==None:\n",
    "        return '<UNK>'\n",
    "    else:\n",
    "        return decode_dict.get(idx)\n",
    "\n",
    "def decode_sequence(seq, decode_dict):\n",
    "    return [get_word_from_idx(j, decode_dict) for j in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = encode_sequence(tokenized_context[1],fr_word2idx)\n",
    "#idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD>']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = decode_sequence([0],fr_idx2word)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 113)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build decoder targets\n",
    "for i, seq in enumerate(tokenized_context):\n",
    "    new_seq = pad_sequences([encode_sequence(seq, fr_word2idx)], padding='post', maxlen=max_out_len)\n",
    "    if i==0:\n",
    "        decoder_output_sequences = new_seq\n",
    "    else:\n",
    "        decoder_output_sequences = np.vstack((decoder_output_sequences, new_seq))\n",
    "        \n",
    "#decoder_output_sequences = numpy.array([numpy.array(xi) for xi in x])\n",
    "\n",
    "decoder_output_sequences.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   73,     9,    69,     6,   444,     8,   421,     6,    10,\n",
       "        1116,   769,     3,     7,  1786,    13,   685,     4,    34,\n",
       "         132,    22,    10,   179,    11,   662,     6,  4906,    19,\n",
       "         195,    22,    50,   685,     8, 10181,    83,   705,     5,\n",
       "           2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode_sequence(decoder_output_sequences[1],fr_idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2YdfpK3O_pY"
   },
   "outputs": [],
   "source": [
    "# configure problem\n",
    "embedings_dim = encoder_input_sequences.shape[2]\n",
    "hidden_units = 512\n",
    "LR = 0.001\n",
    "dropout = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z4-m7zcw2hqV",
    "outputId": "79978b94-9eca-418b-c4a7-1c1d20d1f710"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 512, 83332, 96, 113, 0.001, 0.4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedings_dim, hidden_units, num_words_output, max_input_len, max_out_len, LR, dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nUQk9hA3bfZE"
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "def seq2seq_model(embedings_dim, hidden_units, num_fr_tokens, max_input_len, max_out_len, LR, dropout):      \n",
    "    \n",
    "    encoder_inputs = layers.Input(shape=(max_input_len, embedings_dim,), name='encoder_input')\n",
    "    #encoder_embeddings = layers.Embedding(num_en_tokens, embedings_dim, mask_zero=True)\n",
    "    #encoder_embedded = encoder_embeddings(encoder_inputs)\n",
    "    encoder_bilstm = layers.Bidirectional(layers.LSTM(hidden_units, return_state=True, dropout=dropout), name='encoder_BiLSTM')\n",
    "    # Return states in addition to output\n",
    "    output, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_inputs) # replace embeddings by the encoder input\n",
    "    \n",
    "    state_h = concatenate([forward_h, backward_h])\n",
    "    state_c = concatenate([forward_c, backward_c])\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    #encoder_states = [forward_h, forward_c, backward_h, backward_c]\n",
    "\n",
    "    # Decoder\n",
    "    decoder_inputs = layers.Input(shape=(max_out_len, embedings_dim,), name='decoder_input')\n",
    "    #decoder_embeddings = layers.Embedding(num_fr_tokens, embedings_dim, mask_zero=True)\n",
    "    #decoder_embedded = decoder_embeddings(decoder_inputs)\n",
    "\n",
    "    # Pass the 2 states to a new LSTM layer, as initial state\n",
    "    decoder_lstm = layers.LSTM(hidden_units*2, return_sequences=True, return_state=True, dropout=dropout, name='decoder_LSTM')\n",
    "    decoder_outputs, _, _, = decoder_lstm(decoder_inputs, initial_state=encoder_states) #replace embeddings by decoder inputs\n",
    "\n",
    "    decoder_dense = layers.Dense(num_fr_tokens, activation='linear', name='decoder_output')                     \n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    # Set Optimizer\n",
    "    #opt = tf.keras.optimizers.SGD(lr=0.1, decay=1e-5, momentum=0.9, nesterov=True) #Adam(learning_rate=LR)\n",
    "    # k.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none'),\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-3), #momentum=0.9, nesterov=True),\n",
    "                  metrics=['sparse_categorical_accuracy'],             \n",
    "                 )\n",
    "    model.summary()\n",
    "    \n",
    "    # Evaluation model:\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_h = layers.Input(shape=(hidden_units*2,))\n",
    "    decoder_state_c = layers.Input(shape=(hidden_units*2,))\n",
    "    #decoder_state_b_h = layers.Input(shape=(hidden_units,))\n",
    "    #decoder_state_b_c = layers.Input(shape=(hidden_units,))\n",
    "    \n",
    "    #e_state_h = layers.Concatenate()([decoder_state_f_h, decoder_state_b_h])\n",
    "    #e_state_c = layers.Concatenate()([decoder_state_f_c, decoder_state_b_c])\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_h, decoder_state_c]#, decoder_state_b_h, decoder_state_b_c]\n",
    "    \n",
    "    decoder_inputs_single = layers.Input(shape=(max_out_len, embedings_dim,)) #layers.Input(shape=(1,))\n",
    "    #decoder_inputs_single_x = decoder_embeddings(decoder_inputs_single)\n",
    "    decoder_outputs, h, c = decoder_lstm(decoder_inputs_single, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [h, c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs_single] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states\n",
    "    )\n",
    "     \n",
    "    \n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0418 16:39:43.262333 47064174883840 deprecation.py:506] From /home/guest142/env2/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0418 16:39:43.263807 47064174883840 deprecation.py:506] From /home/guest142/env2/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0418 16:39:43.264656 47064174883840 deprecation.py:506] From /home/guest142/env2/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0418 16:39:43.296069 47064174883840 deprecation.py:506] From /home/guest142/env2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 96, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_BiLSTM (Bidirectional)  [(None, 1024), (None 3149824     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, 113, 256)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           encoder_BiLSTM[0][1]             \n",
      "                                                                 encoder_BiLSTM[0][3]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           encoder_BiLSTM[0][2]             \n",
      "                                                                 encoder_BiLSTM[0][4]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_LSTM (LSTM)             [(None, 113, 1024),  5246976     decoder_input[0][0]              \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 113, 83332)   85415300    decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 93,812,100\n",
      "Trainable params: 93,812,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, encoder_model, decoder_model = seq2seq_model(embedings_dim, hidden_units, num_words_output, max_input_len, max_out_len, LR, dropout)\n",
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ELMO_weights_TF120200418-163945_.hdf5', 'ELMO_history_TF120200418-163945')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_file = \"ELMO_weights_TF1\"+ dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\"_.hdf5\"\n",
    "history_file = \"ELMO_history_TF1\"+ dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "weights_file, history_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11000, 113), (11000, 96, 256), (11000, 113, 256))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_sequences.shape, encoder_input_sequences.shape, decoder_input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 113, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_sequences = np.expand_dims(decoder_output_sequences, -1)\n",
    "decoder_output_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder_input_sequences)*.8/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJVGoHjsO_pi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0418 16:39:46.897715 47064174883840 deprecation.py:323] From /home/guest142/env2/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8800 samples, validate on 2200 samples\n",
      "Epoch 1/20\n",
      "8800/8800 [==============================] - 739s 84ms/sample - loss: 1.4211 - sparse_categorical_accuracy: 0.8211 - val_loss: 1.0330 - val_sparse_categorical_accuracy: 0.8405\n",
      "Epoch 2/20\n",
      "8800/8800 [==============================] - 734s 83ms/sample - loss: 0.9126 - sparse_categorical_accuracy: 0.8493 - val_loss: 0.8808 - val_sparse_categorical_accuracy: 0.8552\n",
      "Epoch 3/20\n",
      "8800/8800 [==============================] - 734s 83ms/sample - loss: 0.7718 - sparse_categorical_accuracy: 0.8601 - val_loss: 0.8050 - val_sparse_categorical_accuracy: 0.8642\n",
      "Epoch 4/20\n",
      "8800/8800 [==============================] - 735s 83ms/sample - loss: 0.6803 - sparse_categorical_accuracy: 0.8680 - val_loss: 0.7607 - val_sparse_categorical_accuracy: 0.8706\n",
      "Epoch 5/20\n",
      "8800/8800 [==============================] - 735s 83ms/sample - loss: 0.6126 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.7328 - val_sparse_categorical_accuracy: 0.8752\n",
      "Epoch 6/20\n",
      "8800/8800 [==============================] - 735s 84ms/sample - loss: 0.5613 - sparse_categorical_accuracy: 0.8799 - val_loss: 0.7146 - val_sparse_categorical_accuracy: 0.8783\n",
      "Epoch 7/20\n",
      "8800/8800 [==============================] - 735s 84ms/sample - loss: 0.5202 - sparse_categorical_accuracy: 0.8859 - val_loss: 0.7009 - val_sparse_categorical_accuracy: 0.8811\n",
      "Epoch 8/20\n",
      "8800/8800 [==============================] - 736s 84ms/sample - loss: 0.4865 - sparse_categorical_accuracy: 0.8913 - val_loss: 0.6904 - val_sparse_categorical_accuracy: 0.8831\n",
      "Epoch 9/20\n",
      "8800/8800 [==============================] - 736s 84ms/sample - loss: 0.4580 - sparse_categorical_accuracy: 0.8964 - val_loss: 0.6831 - val_sparse_categorical_accuracy: 0.8842\n",
      "Epoch 10/20\n",
      "8800/8800 [==============================] - 737s 84ms/sample - loss: 0.4346 - sparse_categorical_accuracy: 0.9011 - val_loss: 0.6758 - val_sparse_categorical_accuracy: 0.8861\n",
      "Epoch 11/20\n",
      "8800/8800 [==============================] - 741s 84ms/sample - loss: 0.4147 - sparse_categorical_accuracy: 0.9051 - val_loss: 0.6719 - val_sparse_categorical_accuracy: 0.8873\n",
      "Epoch 12/20\n",
      "8800/8800 [==============================] - 741s 84ms/sample - loss: 0.3981 - sparse_categorical_accuracy: 0.9083 - val_loss: 0.6675 - val_sparse_categorical_accuracy: 0.8879\n",
      "Epoch 13/20\n",
      "8800/8800 [==============================] - 741s 84ms/sample - loss: 0.3834 - sparse_categorical_accuracy: 0.9114 - val_loss: 0.6632 - val_sparse_categorical_accuracy: 0.8887\n",
      "Epoch 14/20\n",
      "8800/8800 [==============================] - 738s 84ms/sample - loss: 0.3710 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.6607 - val_sparse_categorical_accuracy: 0.8896\n",
      "Epoch 15/20\n",
      "8800/8800 [==============================] - 736s 84ms/sample - loss: 0.3600 - sparse_categorical_accuracy: 0.9161 - val_loss: 0.6586 - val_sparse_categorical_accuracy: 0.8903\n",
      "Epoch 16/20\n",
      "8800/8800 [==============================] - 737s 84ms/sample - loss: 0.3503 - sparse_categorical_accuracy: 0.9181 - val_loss: 0.6562 - val_sparse_categorical_accuracy: 0.8909\n",
      "Epoch 17/20\n",
      "8800/8800 [==============================] - 734s 83ms/sample - loss: 0.3408 - sparse_categorical_accuracy: 0.9201 - val_loss: 0.6542 - val_sparse_categorical_accuracy: 0.8917\n",
      "Epoch 18/20\n",
      "8800/8800 [==============================] - 734s 83ms/sample - loss: 0.3329 - sparse_categorical_accuracy: 0.9220 - val_loss: 0.6535 - val_sparse_categorical_accuracy: 0.8921\n",
      "Epoch 19/20\n",
      "8800/8800 [==============================] - 734s 83ms/sample - loss: 0.3253 - sparse_categorical_accuracy: 0.9234 - val_loss: 0.6515 - val_sparse_categorical_accuracy: 0.8925\n",
      "Epoch 20/20\n",
      "8800/8800 [==============================] - 734s 83ms/sample - loss: 0.3189 - sparse_categorical_accuracy: 0.9246 - val_loss: 0.6496 - val_sparse_categorical_accuracy: 0.8929\n"
     ]
    }
   ],
   "source": [
    "#checkpointer = tf.compat.v2.keras.callbacks.ModelCheckpoint(filepath = weights_file, verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit([encoder_input_sequences, decoder_input_sequences],\n",
    "                    decoder_output_sequences,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs, \n",
    "                    #validation_steps=batch_size,\n",
    "                    validation_split=0.2,\n",
    "                    #callbacks=[checkpointer]\n",
    "                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(history_file, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = pickle.load(open(history_file, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history2['sparse_categorical_accuracy'])\n",
    "plt.plot(history2['val_sparse_categorical_accuracy'])\n",
    "plt.title('model/ accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history2['loss'])\n",
    "plt.plot(history2['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the weights\n",
    "#model.load_weights('ELMO_weights_20200416-042652_.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import plot_model\n",
    "#plot_model(model, to_file = \"seq2seq_translation.png\", show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elmo_emb2(idx):\n",
    "    return encoder_input_sequences[idx].reshape(-1,96,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.9377234 ,  0.11211856, -1.815702  , ..., -1.0165986 ,\n",
       "          0.2566865 , -1.4266841 ],\n",
       "        [ 0.76397216, -0.72957176, -1.2059255 , ..., -0.53055835,\n",
       "         -0.28045744, -1.6430402 ],\n",
       "        [-0.09817386, -2.4250271 ,  1.2986397 , ...,  0.80349994,\n",
       "          0.70233214, -3.0202804 ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_elmo_emb2(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elmo_emb(input_seq, max_length, options_file, weight_file, vocab_file):\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Create a Batcher to map text to character ids.\n",
    "    batcher = Batcher(vocab_file, 50)\n",
    " \n",
    "    # Input placeholders to the biLM.\n",
    "    context_character_ids = tf.compat.v1.placeholder('int32', shape=(None, None, 50))\n",
    " \n",
    "    # Build the biLM graph.\n",
    "    bilm = BidirectionalLanguageModel(options_file, weight_file)\n",
    " \n",
    "    # Get ops to compute the LM embeddings.\n",
    "    context_embeddings_op = bilm(context_character_ids)\n",
    "     \n",
    "    # Get an op to compute ELMo (weighted average of the internal biLM layers)\n",
    "    elmo_context_input = weight_layers('input', context_embeddings_op, l2_coef=0.0)\n",
    "    \n",
    "    # Now we can compute embeddings.\n",
    "    #print(\"get elmo: input_seq=\",input_seq)\n",
    "    tokenized_context = [input_seq.split()] # for sentence in input_seq]\n",
    "    #print(tokenized_context)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # It is necessary to initialize variables once before running inference.\n",
    "        sess.run(tf.global_variables_initializer())\n",
    " \n",
    "        # Create batches of data.\n",
    "        context_ids = batcher.batch_sentences(tokenized_context)\n",
    "        #print(\"Shape of context ids = \", context_ids.shape)\n",
    " \n",
    "        # Compute ELMo representations (here for the input only, for simplicity).\n",
    "        elmo_context_input_ = sess.run(\n",
    "            elmo_context_input['weighted_op'],\n",
    "            feed_dict={context_character_ids: context_ids}\n",
    "        )\n",
    "    # Pad the output to max sequence length of the model\n",
    "    elmo_emb = pad_sequences(elmo_context_input_, maxlen=max_length, padding='post', dtype='float32')\n",
    "    #print(\"Shape of generated embeddings = \",elmo_emb.shape)\n",
    "    return elmo_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(idx, sentence):\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    #tf.reset_default_graph()\n",
    "    global graph\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    \n",
    "    # Get ELMo embeddings\n",
    "    print(\"Get ELMo context for the input sentence: \", sentence)\n",
    "    input_seq = get_elmo_emb(sentence, max_input_len, en_options_file, en_weight_file, en_vocab_file)  # get ELMO embeddings calculated beforehand on input text\n",
    "    #print(input_seq)\n",
    "    \n",
    "    # Get encoder states value\n",
    "    print(\"Feed input context encoder model ...\")\n",
    "    with graph.as_default():\n",
    "        states_value = encoder_model.predict(input_seq)\n",
    "    #print(\"states_value=\",states_value[0].shape)\n",
    "    \n",
    "    # Feed the decoder a token at the time, starting with <S> token\n",
    "    print(\"Feed the decoder with start token ...\")\n",
    "    target_seq = get_elmo_emb('<S>', max_out_len, fr_options_file, fr_weight_file, fr_vocab_file) #['<S>']\n",
    "    \n",
    "    eos1 = fr_word2idx['</S>']\n",
    "    eos2 = fr_word2idx['.']\n",
    "    eos3 = fr_word2idx['<PAD>']\n",
    "    output_sentence = []\n",
    "    \n",
    "    print(\"Translating the input ...\")\n",
    "    for _ in range(max_out_len):\n",
    "        #print(\"Next target_seq=\",target_seq.shape)\n",
    "        with graph.as_default():\n",
    "            output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "        #print(\"new idx=\",idx)\n",
    "        \n",
    "        if ((eos1 == idx) or (eos2 == idx) or (idx==0)):\n",
    "            break\n",
    "        else:\n",
    "            word = decode_sequence([idx],fr_idx2word) #fr_idx2word(idx)\n",
    "            output_sentence.append(word[0]+\" \")\n",
    "            #print(\"Predicting word \"+str(word)+\"for index \"+str(idx))\n",
    "\n",
    "        target_seq = get_elmo_emb(word[0],max_out_len, fr_options_file, fr_weight_file, fr_vocab_file)\n",
    "        states_value = [h, c]\n",
    "        \n",
    "        \n",
    "\n",
    "    return ' '.join(str(v) for v in output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load test data\n",
    "input_text = []\n",
    "with open(en_text_file, 'r', encoding=\"UTF-8\") as en_file:\n",
    "    for line in en_file.readlines():\n",
    "        line = line.rstrip().split('\\n')\n",
    "        input_text.append(line[0])\n",
    "    en_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_text = []\n",
    "with open(fr_text_file, 'r', encoding=\"UTF-8\") as fr_file:\n",
    "    for line in fr_file.readlines():\n",
    "        line = line.rstrip().split('\\n')\n",
    "        target_text.append(line[0])\n",
    "    fr_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.random.randint(0,100,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [target_text[i] for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 96, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_BiLSTM (Bidirectional)  [(None, 1024), (None 3149824     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, 113, 256)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           encoder_BiLSTM[0][1]             \n",
      "                                                                 encoder_BiLSTM[0][3]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           encoder_BiLSTM[0][2]             \n",
      "                                                                 encoder_BiLSTM[0][4]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_LSTM (LSTM)             [(None, 113, 1024),  5246976     decoder_input[0][0]              \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 113, 83332)   85415300    decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 93,812,100\n",
      "Trainable params: 93,812,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "==============================\n",
      "Get ELMo context for the input sentence:  so too does the idea that accommodating religious differences is dangerous\n",
      "USING SKIP CONNECTIONS\n",
      "Feed input context encoder model ...\n",
      "Feed the decoder with start token ...\n",
      "USING SKIP CONNECTIONS\n",
      "Translating the input ...\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "Response:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 96, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_BiLSTM (Bidirectional)  [(None, 1024), (None 3149824     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, 113, 256)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           encoder_BiLSTM[0][1]             \n",
      "                                                                 encoder_BiLSTM[0][3]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           encoder_BiLSTM[0][2]             \n",
      "                                                                 encoder_BiLSTM[0][4]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_LSTM (LSTM)             [(None, 113, 1024),  5246976     decoder_input[0][0]              \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 113, 83332)   85415300    decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 93,812,100\n",
      "Trainable params: 93,812,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "==============================\n",
      "Get ELMo context for the input sentence:  mr president ladies and gentlemen the financial perspective outlines the scope of the eu ’s activities over coming years as well as providing a framework for such activities and determining how effective they will be\n",
      "USING SKIP CONNECTIONS\n",
      "Feed input context encoder model ...\n",
      "Feed the decoder with start token ...\n",
      "USING SKIP CONNECTIONS\n",
      "Translating the input ...\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "Response:\n"
     ]
    }
   ],
   "source": [
    "# Run prediction on 5 samples\n",
    "predictions = []\n",
    "for i in [0,1]:\n",
    "    _, encoder_model, decoder_model = seq2seq_model(embedings_dim, hidden_units, num_words_output, max_input_len, max_out_len, LR, dropout)\n",
    "    graph = tf.get_default_graph()\n",
    "    print('==============================')\n",
    "    #print('Input:', input_text[i])\n",
    "    translation = translate_sentence(i, input_text[i])\n",
    "    print('Response:', )\n",
    "    predictions.append(translation+'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"targets.txt\", \"w\", encoding='utf-8') as target_file:\n",
    "    target_file.writelines(target_text)\n",
    "    target_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions.txt\", \"w\", encoding='utf-8') as target_file:\n",
    "    target_file.writelines(predictions)\n",
    "    target_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eq0ggv-VO_py"
   },
   "source": [
    "## SacreBLEU Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"evaluator.py\", line 71, in <module>\n",
      "    main()\n",
      "  File \"evaluator.py\", line 63, in main\n",
      "    compute_bleu(args.input_file_path, args.target_file_path, args.print_all_scores)\n",
      "  File \"evaluator.py\", line 40, in compute_bleu\n",
      "    stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/subprocess.py\", line 472, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/subprocess.py\", line 775, in __init__\n",
      "    restore_signals, start_new_session)\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/subprocess.py\", line 1522, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'sacrebleu': 'sacrebleu'\n"
     ]
    }
   ],
   "source": [
    "!python evaluator.py --input-file-path predictions.txt --target-file-path targets.txt --do-not-run-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['0.0', '']\n",
    "final avg bleu score: 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Project2_baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
